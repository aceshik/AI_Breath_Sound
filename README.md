 # AI ê¸°ë°˜ í˜¸í¡ ë¶„ì„ ì‹œìŠ¤í…œ ê°œë°œ
## Development of an AI-based respiratory analysis system
### ê¹€ë¬¸ì¢…, ì›ì˜ì‹, ìµœì •ì—°

### êµ¬ì¡°

```bash
AI_BREATH_SOUND/
â”œâ”€â”€ .venv/                        # ê°€ìƒí™˜ê²½ (Python 3.13)
â”‚
â”œâ”€â”€ analysis/                     # ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ analyze_confusion.py
â”‚   â”œâ”€â”€ analyze_thresholds.py
â”‚   â””â”€â”€ analyze_thresholds_mk1.py
â”‚
â”œâ”€â”€ augmentation/                # ë°ì´í„° ì¦ê°•
â”‚   â”œâ”€â”€ augment_crackle.py
â”‚   â””â”€â”€ augment_wheeze.py
â”‚
â”œâ”€â”€ data/                         # ë°ì´í„°ì…‹ ë° ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
â”‚   â”œâ”€â”€ processed/                # ì „ì²˜ë¦¬ëœ ì¤‘ê°„ ë°ì´í„°(ex.ì •ê·œí™”, í•„í„°ë§ëœ ë°ì´í„°)
â”‚   â”œâ”€â”€ raw_audio/                # ì›ë³¸ ì˜¤ë””ì˜¤ ë°ì´í„°(ICBHI 2017 ë“±)
â”‚   â”œâ”€â”€ segments/                 # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°(X.npy, y.npy etc)
â”‚   â””â”€â”€ segments_augmented/       # ì¦ê°•ëœ segment ë°ì´í„°ë“¤
â”‚       â”œâ”€â”€ X_augmented.npy
â”‚       â”œâ”€â”€ X_balanced.npy
â”‚       â”œâ”€â”€ y_augmented.npy
â”‚       â””â”€â”€ y_balanced.npy
â”‚
â”œâ”€â”€ images/                       # ì‹œê°í™” ê²°ê³¼ ì´ë¯¸ì§€ (confusion matrix ë“±)
â”‚
â”œâ”€â”€ models/                       # ëª¨ë¸ êµ¬ì¡° ë° í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸(êµ³ì´ í•„ìš” ì—†ëŠ” íŒŒì¼ë“¤ ë‚ ë¦¼)
â”‚   â”œâ”€â”€ cnn_lstm_model.py
â”‚   â”œâ”€â”€ cnn_lstm_model_mk1.py
â”‚   â””â”€â”€ train_model.py            
â”‚
â”œâ”€â”€ notebooks/                    # (ë¹„ì–´ìˆìŒ ë˜ëŠ” Jupyter ì‘ì—… ê³µê°„)
â”‚
â”œâ”€â”€ preprocessing/                # ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ balance_sampling.py
â”‚   â”œâ”€â”€ extract_features.py
â”‚   â”œâ”€â”€ parse_icbhi_labels.py
â”‚   â”œâ”€â”€ preprocess_icbhi.py
â”‚   â””â”€â”€ split_segments.py
â”‚
â”œâ”€â”€ results/                      # ì˜ˆì¸¡ ê²°ê³¼, í•™ìŠµê²°ê³¼
â”‚   â”œâ”€â”€ train_losses.npy
â”‚   â”œâ”€â”€ val_losses.npy
â”‚   â”œâ”€â”€ y_pred_probs.npy
â”‚   â””â”€â”€ y_true.npy
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ log.md                        # ì‹¤í—˜ ë¡œê·¸ ë©”ëª¨
â”œâ”€â”€ notepad.py                    # ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ / ì‹¤í—˜ìš©
â”œâ”€â”€ README.md                     # í”„ë¡œì íŠ¸ ì„¤ëª…
â””â”€â”€ requirements.txt              # íŒ¨í‚¤ì§€ ì˜ì¡´ì„± ëª©ë¡
```

# í˜„ì¬ê¹Œì§€ êµ¬í˜„ìƒí™©

- ICBHI 2017 ë°ì´í„°ì…‹ êµ¬ì„± ë¶„ì„ ë° ì •ë¦¬
- '.wav' ì˜¤ë””ì˜¤ íŒŒì¼ ë¬´ìŒ ì œê±° + ì •ê·œí™”
- '.txt' ë¼ë²¨ íŒŒì¼ íŒŒì‹± â†’ 'icbhi_labels.csv'
- í˜¸í¡ ì£¼ê¸° ë‹¨ìœ„ë¡œ '.wav' íŒŒì¼ ë¶„í•  â†’ 'segments/*.wav'
- ë¶„í• ëœ ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜ ë¼ë²¨ë§ â†’ 'segments_labels.csv'
- ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ MFCC íŠ¹ì§• ì¶”ì¶œ â†’ 'X.npy', 'Y.npy' / ìš©ëŸ‰ì´ìŠˆë¡œ ê¹ƒí—ˆë¸Œ í‘¸ì‹œx

- ë°ì´í„° ë¶ˆê· í˜• ì¡°ì • (Undersampling + Oversampling) â†’ `X_balanced.npy`, `y_balanced.npy`
- Crackle í´ë˜ìŠ¤ ë°ì´í„° ì¦ê°• (Noise ì¶”ê°€, Time Stretching ë“±) â†’ `X_balanced.npy`, `y_balanced.npy`
- Wheeze í´ë˜ìŠ¤ ë°ì´í„° ì¦ê°• (Gaussian Noise ì¶”ê°€) â†’ `X_augmented.npy`, `y_augmented.npy`
- CNN+LSTM ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ ì½”ë“œ ì‘ì„± â†’ `models/cnn_lstm_model.py`
- Threshold ìµœì í™” ì‹¤í—˜ (Precision vs Recall ì¡°ì •) â†’ ìµœì  Threshold ì„¤ì •
- ìµœì¢… ëª¨ë¸ í‰ê°€ ë° Classification Report ìƒì„±


<details>
<summary> ë©”ëª¨ </summary>
models/cnn_lstm_model.py ì—ì„œ ëª¨ë¸ í•™ìŠµ í•œ íŒŒì¼ results/ ì— ì €ì¥í•˜ê³ 
ê·¸ê±° ë¶ˆëŸ¬ì™€ì„œ
analysis/analyze_thresholds.py ì—ì„œ thresholds ë­˜ë¡œ í•˜ëŠ”ê²Œ ì œì¼ ë‚˜ì€ì§€ ê³„ì† ëŒë ¤ì•¼í•¨

crackle ì¦ê°•í•˜ë‹ˆê¹Œ ì—„ì²­ ì˜ë‚˜ì˜¤ê³ 
wheezeëŠ” ì›ë˜ ì•½í–ˆì–´ì„œ
wheezeê¹Œì§€ ì¦ê°•í–ˆëŠ”ë°

wheeze ê°œì„ì§€ê³ 
crackle ê°œì•½í•´ì§

ê°œìˆ˜ê°€ ì•ˆë§ëŠ”ê±°ê°™ì•„ì„œ crackle ê°œìˆ˜ ëŠ˜ë¦¬ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í–‰í•´ì•¼í• ë“¯

crackle ì¦ê°•ì— wheeze ì¦ê°• ë”í•˜ë‹ˆê¹Œ ì—„ì²­ì„ì§! ì°¨ê·¼ì°¨ê·¼ ë³¼ê²ƒ.

ë°ì´í„° ë¶ˆê· í˜• ì¡ì€ê±° x_balancedê³ 
crackle ì¦ê°•í•œê²ƒë„ x_balancedë‹ˆê¹Œ ê³ ì¹˜ê¸°~
</details>


### Classification Report

| Metric         | Wheeze  | Crackle | Micro Avg | Macro Avg | Weighted Avg | Samples Avg |
|---------------|--------|--------|-----------|-----------|-------------|-------------|
| **Precision**  | 0.69   | 0.75   | 0.72      | 0.72      | 0.72        | 0.71        |
| **Recall**     | 0.93   | 1.00   | 0.96      | 0.96      | 0.96        | 0.87        |
| **F1-score**   | 0.79   | 0.86   | 0.83      | 0.82      | 0.83        | 0.76        |
| **Support**    | 2982   | 3432   | 6414      | 6414      | 6414        | 6414        |

> **ìœ ì˜ë¯¸í•œ ê²°ê³¼ ê¸°ì¤€**  
> - **Precision â‰¥ 0.70**: ì„ìƒì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€  
> - **Recall â‰¥ 0.90**: ì¤‘ìš”í•œ ì˜ë£Œ ì‹ í˜¸ë¥¼ ë†“ì¹˜ì§€ ì•ŠëŠ” ìˆ˜ì¤€  
> - **Macro F1-score â‰¥ 0.75**: ì „ì²´ì ì¸ ëª¨ë¸ ì„±ëŠ¥ì´ ì‹¤ìš©ì ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ìˆ˜ì¤€  
> - **Crackle Recall = 1.00**: Crackleì„ ë†“ì¹˜ì§€ ì•ŠëŠ” ì™„ë²½ íƒì§€  

---
# ìƒì„¸ ì§„í–‰ ìƒí™©

## MLP_TRAIN

ì´ˆê¸° MLP ëª¨ë¸ì—ì„œ í•™ìŠµì´ ì œëŒ€ë¡œ ì§„í–‰ë˜ì§€ ì•ŠìŒ â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„°, ì „ì²˜ë¦¬ ì¡°ì •

### ì´ˆê¸°ëª¨ë¸(í•™ìŠµë¥ : 0.001, ì •ê·œí™” ì—†ìŒ)
- í•™ìŠµë¥ (lr): 0.001
- ì…ë ¥ ì •ê·œí™” ì—†ìŒ
- Lossê°€ ì ì  ì»¤ì§€ë©° 27.3ê¹Œì§€ ì¦ê°€
- ëª¨ë¸ ë°œì‚°í•˜ì—¬ í•™ìŠµ ì‹¤íŒ¨

<details>
<summary> ì´ˆê¸° MLP LOSSì–‘ </summary>
[1/20] Train Loss: 1.8743 | Val Loss: 21.0850<br>
[2/20] Train Loss: 21.2713 | Val Loss: 24.0106<br>
[3/20] Train Loss: 24.2620 | Val Loss: 24.3964<br>
[4/20] Train Loss: 24.6545 | Val Loss: 23.5934<br>
[5/20] Train Loss: 23.8299 | Val Loss: 20.7134<br>
[6/20] Train Loss: 20.8538 | Val Loss: 34.3102<br>
[7/20] Train Loss: 33.8169 | Val Loss: 22.5947<br>
[8/20] Train Loss: 22.7939 | Val Loss: 25.2366<br>
[9/20] Train Loss: 25.5058 | Val Loss: 26.2734<br>
[10/20] Train Loss: 26.5680 | Val Loss: 26.6861<br>
[11/20] Train Loss: 27.0117 | Val Loss: 26.8341<br>
[12/20] Train Loss: 27.1842 | Val Loss: 26.8880<br>
[13/20] Train Loss: 27.2585 | Val Loss: 26.9114<br>
[14/20] Train Loss: 27.2955 | Val Loss: 26.9172<br>
[15/20] Train Loss: 27.3090 | Val Loss: 26.9243<br>
[16/20] Train Loss: 27.3177 | Val Loss: 26.9269<br>
[17/20] Train Loss: 27.3239 | Val Loss: 26.9292<br>
[18/20] Train Loss: 27.3270 | Val Loss: 26.9313<br>
[19/20] Train Loss: 27.3287 | Val Loss: 26.9332<br>
[20/20] Train Loss: 27.3309 | Val Loss: 26.9350<br>
</details>

### ê°œì„ ëœ ëª¨ë¸(í•™ìŠµë¥  ê°ì†Œ + ì •ê·œí™”)
- í•™ìŠµë¥ (lr): 0.0001 (1e-4)
- ì…ë ¥ ì •ê·œí™” ì¶”ê°€:
```python
  X = (X - X.mean()) / X.std()
  ```

<details>
<summary> ê°œì„  MLP LOSSì–‘ </summary>
[1/20] Train Loss: 0.6941 | Val Loss: 0.6722<br>
[2/20] Train Loss: 0.6721 | Val Loss: 0.6537<br>
[3/20] Train Loss: 0.6542 | Val Loss: 0.6381<br>
[4/20] Train Loss: 0.6390 | Val Loss: 0.6249<br>
[5/20] Train Loss: 0.6263 | Val Loss: 0.6137<br>
[6/20] Train Loss: 0.6155 | Val Loss: 0.6042<br>
[7/20] Train Loss: 0.6064 | Val Loss: 0.5963<br>
[8/20] Train Loss: 0.5991 | Val Loss: 0.5903<br>
[9/20] Train Loss: 0.5937 | Val Loss: 0.5861<br>
[10/20] Train Loss: 0.5901 | Val Loss: 0.5835<br>
[11/20] Train Loss: 0.5882 | Val Loss: 0.5821<br>
[12/20] Train Loss: 0.5874 | Val Loss: 0.5815<br>
[13/20] Train Loss: 0.5872 | Val Loss: 0.5810<br>
[14/20] Train Loss: 0.5872 | Val Loss: 0.5805<br>
[15/20] Train Loss: 0.5870 | Val Loss: 0.5798<br>
[16/20] Train Loss: 0.5864 | Val Loss: 0.5788<br>
[17/20] Train Loss: 0.5855 | Val Loss: 0.5776<br>
[18/20] Train Loss: 0.5843 | Val Loss: 0.5762<br>
[19/20] Train Loss: 0.5828 | Val Loss: 0.5747<br>
[20/20] Train Loss: 0.5812 | Val Loss: 0.5732<br>
</details>

### ê°œì„ ëœ ëª¨ë¸ í‰ê°€ ì§„í–‰í–ˆìœ¼ë‚˜ ë°ì´í„° ë¶ˆê· í˜•ìœ¼ë¡œ ëª¨ë‘ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡
### ëª©í‘œ: ì˜ˆì¸¡ ì„±ëŠ¥ì„ ìµœëŒ€í•œ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒ

###  ì‹¤í—˜ #1: Dropout ì œê±°
- êµ¬ì¡°: ê¸°ë³¸ CNN
- ê²°ê³¼:
  - Wheeze Precision: 0.44 â†’ Recall: 0.85
  - Crackle Precision: 0.27 â†’ Recall: 0.51
  - **Macro F1-score: 0.46 (ì†Œí­ í–¥ìƒ)**

---

###  ì‹¤í—˜ #2: ë°ì´í„° ë¶ˆê· í˜• ì™„í™”
- ë°©ë²•: Undersampling + Oversampling ì¡°í•©
- ê²°ê³¼:
  - Wheeze Precision: 0.54 / Recall: 0.90
  - Crackle Precision: 0.52 / Recall: 0.76
  - **Macro F1-score: 0.64 (ì˜ë¯¸ ìˆëŠ” í–¥ìƒ)**

---

###  ì‹¤í—˜ #3: CNN êµ¬ì¡° ì¡°ì •
- êµ¬ì¡°: í•„í„° ìˆ˜ ì¦ê°€ + Dropout ì¶”ê°€/ì œê±° ë¹„êµ

#### 3-1. Dropout í¬í•¨
- Macro F1-score: 0.64

#### 3-2. Dropout ì œê±°
- Wheeze Precision: 0.59 / Recall: 0.79  
- Crackle Precision: 0.47 / Recall: 0.90  
- **Macro F1-score: 0.64 (ë™ì¼)**  
- **Dropout ì œê±° ì‹œ Precisionì´ ë” ë†’ìŒ** â†’ ì„ íƒ

### LSTM ì¶”ê°€ (CNN + LSTM)
- CNNë§Œìœ¼ë¡œëŠ” ì„±ëŠ¥ í–¥ìƒ í•œê³„ ë„ë‹¬
- ë°ì´í„°: ë¶ˆê· í˜• ì¡°ì •ëœ ë²„ì „ ì‚¬ìš©
- í•™ìŠµì‹œê°„: ë³µì¡ì„±ì´ ì»¤ì ¸ ë” ì˜¤ë˜ê±¸ë¦¼
- ì´ˆê¸° ì†ì‹¤ëŸ‰: 0.6828(í™•ì—°íˆ ë‚®ì•„ì§)

---

### ìƒˆë¡œìš´ ë°ì´í„° ì „ì²˜ë¦¬
ë°ì´í„° ë¶ˆê· í˜• ì¡°ì •
- X_balanced.npy, y_balanced.npy ì‚¬ìš© (undersampling + oversampling)
- ì •ê·œí™” (X - mean) / std
- ì°¨ì› ë³´ì •: (N, 13, 100) â†’ (N, 1, 13, 100)
- Train/Val ë¶„ë¦¬: test_size = 0.2, random_state = 42

### ëª¨ë¸ êµ¬ì¡°: CNN + BiLSTM

```bash
Conv2d â†’ ReLU â†’ MaxPool2d  
Conv2d â†’ ReLU â†’ MaxPool2d  
â†“  
Reshape to (batch, seq_len, input_size)  
â†“  
Bidirectional LSTM  
â†“  
Linear â†’ 2 logits (Wheeze, Crackle)
```
- LSTM input size: 64, hidden size: 64, bidirectional
- BCEWithLogitsLoss ì‚¬ìš© (pos_weight ì¡°ì • ê°€ëŠ¥)

### í•™ìŠµ ì„¤ì •
- Optimizer: Adam(lr=0.001)
- Epochs: 20
- Batch size: 32
- ì†ì‹¤ ê¸°ë¡ ë° ì‹œê°í™” ì €ì¥

### Threshold íŠœë‹
- íƒìƒ‰ ë²”ìœ„: [0.2, 0.25, ..., 0.60]
- ê¸°ì¤€: Macro F1 ìµœì¬í™”
- ìµœì  ê²°ê³¼
```bash
Wheeze â‰¥ 0.25, Crackle â‰¥ 0.25 â†’ Macro F1 â‰ˆ 0.6229
```
Crackle Precisionì´ ê³„ì† ë„ˆë¬´ ë‚®ê²Œ ë‚˜ì˜´ â†’

### Crackle Precision ê°œì„ 
- analysis/analyze_crackle_errors.py
- False Positive ì˜ˆì‹œ 10ê±´ ì¶œë ¥
- ë³„ë„ ë¶„ì„ ì½”ë“œ: analyze_thresholds.py ìƒì„±

### Crackle Threshold ì¬íƒìƒ‰ ê²°ê³¼

| Crackle Threshold | Macro F1 | Crackle Precision |
|-------------------|----------|-------------------|
| 0.30              | 0.6123   | 0.4072            |
| 0.35              | 0.5468   | 0.5000            |
| 0.40              | 0.5072   | 0.5632            |
| 0.45              | 0.4692   | 0.6193            |
| 0.50              | 0.4306   | 0.6218            |
| 0.55              | 0.4075   | 0.6548            |
| 0.60              | 0.3855   | 0.6610            |

.
.
.

ê²°êµ­ ë°ì´í„° ì¦ê°• í•´ì„œ ì–´ë–»ê²Œë“  í•´ëƒ„


#### ì¼ë‹¨ ì—¬ê¸°ê¹Œì§€ í–ˆìŒ

# ì„±ëŠ¥ í–¥ìƒ ê³¼ì •

### 1 **Baseline Model (ì‹¤í—˜ #1)**
- **Macro F1-score**: 0.46
- **Crackle Precision**: 0.27
- **Crackle Recall**: 0.51
- âœ… **ë¬¸ì œì **: Precisionì´ ë§¤ìš° ë‚®ê³ , Crackle íƒì§€ê°€ ë¶ˆì•ˆì •í•¨.

---

### 2 **ë°ì´í„° ë¶ˆê· í˜• ì¡°ì • (ì‹¤í—˜ #3)**
- **Macro F1-score**: 0.64 (+0.18 ì¦ê°€)
- **Crackle Precision**: 0.52 (+0.25 ì¦ê°€)
- **Crackle Recall**: 0.76 (+0.25 ì¦ê°€)
- âœ… **ê°œì„ ì **: Crackleì´ ë” ì˜ íƒì§€ë˜ì—ˆìœ¼ë©°, Wheezeì™€ Crackleì˜ ê· í˜•ì´ ë§ì¶°ì§.

---

### 3 **CNN êµ¬ì¡° ìµœì í™” + Dropout ì œê±° (ì‹¤í—˜ #4-2)**
- **Macro F1-score**: 0.64 (ë³€í™” ì—†ìŒ)
- **Crackle Precision**: 0.47 (ì†Œí­ ê°ì†Œ)
- **Crackle Recall**: 0.90 (+0.14 ì¦ê°€)
- âœ… **ê°œì„ ì **: Crackleì„ ë” ë†“ì¹˜ì§€ ì•Šë„ë¡ recall í–¥ìƒ.

---

### 4 **CNN+LSTM ë„ì… & Epoch ì¦ê°€ (ì‹¤í—˜ #5)**
- **Macro F1-score**: 0.65 (+0.01 ì¦ê°€)
- **Crackle Precision**: 0.50 (+0.03 ì¦ê°€)
- **Crackle Recall**: 1.00 (+0.10 ì¦ê°€)
- âœ… **ê°œì„ ì **: Crackle íƒì§€ê°€ ì™„ë²½í•´ì§.

---

### 5 **Threshold íŠœë‹ + ë°ì´í„° ì „ë¶€ ì¦ê°• (ì‹¤í—˜ #6)**
- **Macro F1-score**: 0.82 (+0.17 ì¦ê°€)
- **Crackle Precision**: 0.75 (+0.25 ì¦ê°€)
- **Crackle Recall**: 1.00 (ìœ ì§€)
- âœ… **ìµœì¢… ê²°ê³¼**: **ì˜ë£Œì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ì— ë„ë‹¬!** ğŸ‰




## ë‹¤ìŒ ë‹¨ê³„ ê³ ë¯¼ <br>
	1.	ë‹¤ì¤‘ threshold grid íƒìƒ‰ (Wheezeì™€ Crackleì„ ë™ì‹œì— ì¡°ì •í•´ì„œ F1 ìµœëŒ€í™”) <br>
	2.	False Positive ìƒ˜í”Œ ë¶„ì„: precision ê°œì„ ì„ ìœ„í•œ íŒíŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ <br>
	3.	ëª¨ë¸ ì•™ìƒë¸” ì‹œë„: CNN+LSTM ê²°ê³¼ë¥¼ ë‹¤ë¥¸ ëª¨ë¸ê³¼ í‰ê· í•˜ê±°ë‚˜ ë‹¤ìˆ˜ê²° ì²˜ë¦¬ <br>
	4.	ë¦¬í¬íŠ¸ ìë™ ì €ì¥: ê²°ê³¼ë“¤ì„ results/metrics_log.csv ë“±ì— ì •ë¦¬ <br>